{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Creating Spark Session and Loading the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **step 01: Import Spark Session and initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create entry points to spark\n",
    "from pyspark import SparkContext # Spark\n",
    "from pyspark.sql import SparkSession # Spark SQL\n",
    "\n",
    "# We add this line to avoid an error : \"Cannot run multiple SparkContexts at once\". \n",
    "# If there is an existing spark context, we will reuse it instead of creating a new context.\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# local[*]: run Spark locally with as many working processors as logical cores on your machine.\n",
    "# In the field of `master`, we use a local server with as many working processors (or threads) as possible (i.e. `local[*]`). \n",
    "# If we want Spark to run locally with 'k' worker threads, we can specify as `local[k]`.\n",
    "# The `appName` field is a name to be shown on the Sparking cluster UI. \n",
    "\n",
    "# If there is no existing spark context, we now create a new context\n",
    "if (sc is None):\n",
    "    sc = SparkContext(master=\"local[4]\", appName=\"assignment2\")\n",
    "    # Here we create a SparkSession with  local cores \n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 02: Load the dataset and print the schema and total number of entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  142193  entries\n"
     ]
    }
   ],
   "source": [
    "# load the csv file into a dataframe using spark session\n",
    "df = spark.read.csv('weatherAUS.csv',header = True,inferSchema=True)\n",
    "# show the count of entries\n",
    "print(\"There are \",df.count(),\" entries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 03: Delete columns from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "only showing top 0 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create a list containing columns which are not contributing to the rain prediction \n",
    "drop_list = ['Date', \"Location\", 'Evaporation', 'Sunshine',\"Cloud9am\",\"Cloud3pm\",\"Temp9am\",\"Temp3pm\"]\n",
    "# renew dataframe by select columns not in the drop_list\n",
    "df = df.select([column for column in df.columns if column not in drop_list])\n",
    "# to check whether makes it or not\n",
    "df.show(0,truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 04: Print the number of missing data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|    637|    322|    1406|       9330|         9270|     10013|      3778|        1348|        2630|       1774|       3610|      14014|      13981|     1406|           0|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as func\n",
    "#counting the number of rows when value is \"NA\" for each columns done by a for loop\n",
    "count_Null = df.select([func.count(func.when(func.col(c)==\"NA\",c)).alias(c) for c in df.columns])\n",
    "count_Null.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 05: Fill the missing data with average value and maximum occurrence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+------------------+-----------------+---------------+-----------------+----------------+------------------+------------------+------------------+\n",
      "|           MinTemp|         MaxTemp|          Rainfall|    WindGustSpeed|   WindSpeed9am|     WindSpeed3pm|     Humidity9am|       Humidity3pm|       Pressure9am|       Pressure3pm|\n",
      "+------------------+----------------+------------------+-----------------+---------------+-----------------+----------------+------------------+------------------+------------------+\n",
      "|12.186399728729311|23.2267841912725|2.3499740743107442|39.98429165757619|14.001988000994|18.63757586179718|68.8438103105705|51.482606091656265|1017.6537584159615|1015.2582035378894|\n",
      "+------------------+----------------+------------------+-----------------+---------------+-----------------+----------------+------------------+------------------+------------------+\n",
      "\n",
      "['W', 'N', 'SE', 'No', 'No']\n"
     ]
    }
   ],
   "source": [
    "# build a list of Non-numeric columns\n",
    "Non_numeric_col = [\"WindGustDir\",\"WindDir9am\",\"WindDir3pm\",\"RainToday\",\"RainTomorrow\"]\n",
    "# find mean value for each numeric columns\n",
    "mean_value_df = df.select([func.mean(func.col(c)).alias(c) for c in df.columns if c not in Non_numeric_col])\n",
    "meanv = mean_value_df.collect()\n",
    "# find the most frequent item for each columns\n",
    "maxi = [df.filter(df[c] != \"NA\").groupBy(c).count().\\\n",
    "        sort(\"count\",ascending = False).collect()[0][0] for c in Non_numeric_col]\n",
    "\n",
    "# fill in all the missing data with average value (for numeric\n",
    "# column) or maximum frequency value (for non-numeric column).\n",
    "i = 0\n",
    "j = 0\n",
    "for c in df.columns :\n",
    "    if c not in Non_numeric_col:         \n",
    "        df = df.withColumn(c,func.when(func.col(c)==\"NA\",meanv[0][i]).otherwise(func.col(c)))\n",
    "        i += 1\n",
    "        \n",
    "    else:\n",
    "        df = df.replace(\"NA\",maxi[j],c)\n",
    "        j += 1   \n",
    "#To check out the mean value and maximum frequency value have been found properly\n",
    "mean_value_df.show()\n",
    "print(maxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 06: Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MinTemp: double (nullable = true)\n",
      " |-- MaxTemp: double (nullable = true)\n",
      " |-- Rainfall: double (nullable = true)\n",
      " |-- WindGustSpeed: double (nullable = true)\n",
      " |-- WindSpeed9am: double (nullable = true)\n",
      " |-- WindSpeed3pm: double (nullable = true)\n",
      " |-- Humidity9am: double (nullable = true)\n",
      " |-- Humidity3pm: double (nullable = true)\n",
      " |-- Pressure9am: double (nullable = true)\n",
      " |-- Pressure3pm: double (nullable = true)\n",
      " |-- WindGustDir_label: double (nullable = false)\n",
      " |-- WindDir9am_label: double (nullable = false)\n",
      " |-- WindDir3pm_label: double (nullable = false)\n",
      " |-- RainToday_label: double (nullable = false)\n",
      " |-- RainTomorrow_label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "alist = []\n",
    "for c in df.columns :\n",
    "    if c not in Non_numeric_col: \n",
    "        #transforming numerical data into double type\n",
    "        df = df.withColumn(c,df[c].cast(DoubleType()))\n",
    "    else:\n",
    "        #transforming non-numerical data into number by using StringIndexer\n",
    "        alist.append(StringIndexer(inputCol = c, outputCol = c + \"_label\"))\n",
    "        \n",
    "# Fit the pipeline to training documents.       \n",
    "pipeline = Pipeline(stages=alist)\n",
    "pipelineFit = pipeline.fit(df)\n",
    "dataset = pipelineFit.transform(df)\n",
    "\n",
    "#drop original columns whose indexing are done\n",
    "dataset = dataset.select([c for c in dataset.columns if c not in Non_numeric_col])\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 07: Create the feature vector and divide the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bind all feature columns\n",
    "vector_assembler = VectorAssembler(inputCols=[\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"WindGustDir_label\",\"WindGustSpeed\",\\\n",
    "                                              \"WindDir9am_label\",\\\n",
    "                                              \"WindDir3pm_label\",\"WindSpeed9am\",\"WindSpeed3pm\",\"Humidity9am\",\\\n",
    "                                              \"Humidity3pm\",\\\n",
    "                                              \"Pressure9am\",\"Pressure3pm\",\n",
    "                                              \"RainToday_label\",],outputCol = \"features\")\n",
    "#Fit and Evaluate Models\n",
    "pipeline1 = Pipeline(stages= [vector_assembler])\n",
    "pipelineFit1 = pipeline1.fit(dataset)\n",
    "dataset_new = pipelineFit1.transform(dataset)\n",
    "\n",
    "#Split the dataset into training and testing (70%,30%)\n",
    "(trainingData, testData) = dataset_new.randomSplit([0.7, 0.3], seed = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Apply Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 08: Apply machine learning classification algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the rain fall tomorrow is 83.34%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Create an initial model using the train set.\n",
    "dt = DecisionTreeClassifier(labelCol=\"RainTomorrow_label\", featuresCol=\"features\")\n",
    "model1 = dt.fit(trainingData)\n",
    "# test the model\n",
    "predictions1 = model1.transform(testData)\n",
    "# compute accuracy on the test set\n",
    "evaluator =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_label\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy1 = evaluator.evaluate(predictions1)\n",
    "print(\"The probability of the rain fall tomorrow is\",'%.2f%%'%(100*accuracy1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the rain fall tomorrow is 83.30%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Create an initial model using the train set.\n",
    "rf = RandomForestClassifier(labelCol=\"RainTomorrow_label\",featuresCol=\"features\", numTrees=10)\n",
    "model = rf.fit(trainingData)\n",
    "# test the model\n",
    "predictions2 = model.transform(testData)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_label\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy2 = evaluator.evaluate(predictions2)\n",
    "print(\"The probability of the rain fall tomorrow is\",'%.2f%%'%(100*accuracy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the rain fall tomorrow is 81.92%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Create an initial model using the train set.\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'RainTomorrow_label',  maxIter=10)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "# LogicRegression.transform() is a method that uses only 'features'.\n",
    "predictions3 = lrModel.transform(testData)\n",
    "\n",
    "# The MulticlassificationEvaluator is used to evaluate the model.\n",
    "evaluator =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_label\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy3 = evaluator.evaluate(predictions3)\n",
    "print(\"The probability of the rain fall tomorrow is\",'%.2f%%'%(100*accuracy3))\n",
    "\n",
    "### Why the accuracy is not same when applying different evaluator? \n",
    "#   Because  metricNames are not same,in MulticlassificationEvaluator, it is not calculate accuracy by default\n",
    "### Does default by \"label\" , the ml can recognize the word \"label\" ? yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the rain fall tomorrow is 84.04%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "# Create an initial model using the train set.\n",
    "gbt = GBTClassifier(featuresCol = 'features', labelCol = 'RainTomorrow_label', maxIter=10)\n",
    "gbtModel = gbt.fit(trainingData)\n",
    "# test the model\n",
    "predictions4 = gbtModel.transform(testData)\n",
    " \n",
    "#Use the MulticlassClassificationEvaluator method to evaluate the accuracy of the model\n",
    "evaluator =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_label\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy4 = evaluator.evaluate(predictions4)\n",
    "print(\"The probability of the rain fall tomorrow is\",'%.2f%%'%(100*accuracy4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "y = [accuracy1,accuracy2,accuracy3,accuracy4]\n",
    "objects = [\"DecisionTreeClassifier\",\"RandomForestClassifier\",\"LogisticRegression\", \"GBTClassifier\"]\n",
    "y_pos = np.arange(len(objects))\n",
    "plt.bar(y_pos,y)\n",
    "plt.xticks(y_pos, objects,rotation=315)\n",
    "plt.ylim(.8,.86)\n",
    "plt.xlabel('Name of models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of different models')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 09: Calculate the confusion matrix and find the precision, recall, and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "#Build MulticlassMetrics base on 'prediction' and \"RainTomorrow_label\"\n",
    "prediction = [predictions1,predictions2,predictions3,predictions4]\n",
    "ml = [\"DecisionTreeClassifier\", \"RandomForestClassifier\",\"LogisticRegression\", \"GBTClassifier\"]\n",
    "def step09():\n",
    "    for i in range(4):\n",
    "        print(\"This is for \",ml[i])\n",
    "        print(\" \")         \n",
    "        results = p.select(['prediction', \"RainTomorrow_label\"])\n",
    "        predictionAndLabels=results.rdd\n",
    "        metrics = MulticlassMetrics(predictionAndLabels)\n",
    "        \n",
    "        # calculate the Precision,Recall and F1 Score of label valued with 0, which is not raining tomorrow\n",
    "        df = prediction[i]\n",
    "        #  when prediction is not raining and label is not raining, it is true positive\n",
    "        tp = df.filter(df[\"RainTomorrow_label\"] == 0).filter(df[\"prediction\"] == 0).count()\n",
    "        #  when prediction is raining and label is not raining, it is false positive\n",
    "        fp = df.filter(df[\"RainTomorrow_label\"] == 1).filter(df[\"prediction\"] == 0).count()\n",
    "        #  when prediction is not raining and label is raining, it is true negative\n",
    "        fn = df.filter(df[\"RainTomorrow_label\"] == 0).filter(df[\"prediction\"] == 1).count()\n",
    "        #  when prediction is  raining and label is  raining, it is false negative\n",
    "        tn = df.filter(df[\"RainTomorrow_label\"] == 1).filter(df[\"prediction\"] == 1).count()\n",
    "        p = tp/(tp+fp)\n",
    "        r = tp/(tp+fn)\n",
    "        f1 = 2*p*r/(p+r)\n",
    "        # Build a metrix                     \n",
    "        data = [(\"Positive\",float(tp),float(fn)),(\"Negative\",float(fp),float(tn))]\n",
    "        newdf = spark.createDataFrame(data, [\"True value\",\"Positive(predicted)\",\"Negative(predicted)\"])\n",
    "        print(\"Label 0, Not raining tomorrow\")\n",
    "        print(\" \")\n",
    "        newdf.show()\n",
    "\n",
    "        print(\"Precision = %.5f\" % p)\n",
    "        print(\"Recall = %.5f\" % r)\n",
    "        print(\"F1 Score = %.5f\" % f1)\n",
    "        print(\" \")\n",
    "\n",
    "        # calculate the Precision,Recall and F1 Score of label valued with 1, which is raining tomorrow\n",
    "        #  when prediction is raining and label is raining, it is true positive\n",
    "        tp = df.filter(df[\"RainTomorrow_label\"] == 1).filter(df[\"prediction\"] == 1).count()\n",
    "        #  when prediction is not raining and label is raining, it is false positive\n",
    "        fp = df.filter(df[\"RainTomorrow_label\"] == 0).filter(df[\"prediction\"] == 1).count()\n",
    "        #  when prediction is raining and label is not raining, it is true negative\n",
    "        fn = df.filter(df[\"RainTomorrow_label\"] == 1).filter(df[\"prediction\"] == 0).count()\n",
    "        #  when prediction is not raining and label is not raining, it is false negative\n",
    "        tn = df.filter(df[\"RainTomorrow_label\"] == 0).filter(df[\"prediction\"] == 0).count()        \n",
    "        p = tp/(tp+fp)\n",
    "        r = tp/(tp+fn)\n",
    "        f1 = 2*p*r/(p+r)\n",
    "\n",
    "        # # Build a metrix                     \n",
    "        data = [(\"Positive\",float(tp),float(fn)),(\"Negative\",float(fp),float(tn))]\n",
    "        newdf = spark.createDataFrame(data, [\"True value\",\"Positive(predicted)\",\"Negative(predicted)\"])\n",
    "        print(\"Label 1, raining tomorrow\")\n",
    "        print(\" \")\n",
    "        newdf.show()\n",
    "        print(\"Precision = %.5f\" % p)\n",
    "        print(\"Recall = %.5f\" % r)\n",
    "        print(\"F1 Score = %.5f\" % f1)\n",
    "        print(\" \")\n",
    "\n",
    "\n",
    "        # # # Overall statistics\n",
    "        cm=metrics.confusionMatrix().toArray()\n",
    "        precision = metrics.precision()\n",
    "        recall = metrics.recall()\n",
    "        f1Score = metrics.fMeasure()\n",
    "        print(\"Summary Stats for overall\")\n",
    "        print(\"Precision = %.5f\" % precision)\n",
    "        print(\"Recall = %.5f\" % recall)\n",
    "        print(\"F1 Score = %.5f\" % f1Score)\n",
    "        print(\" \")\n",
    "        print(\" \")\n",
    "        print(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is for  DecisionTreeClassifier\n",
      " \n",
      "Label 0, Not raining tomorrow\n",
      " \n",
      "+----------+-------------------+-------------------+\n",
      "|True value|Positive(predicted)|Negative(predicted)|\n",
      "+----------+-------------------+-------------------+\n",
      "|  Positive|            31410.0|             1567.0|\n",
      "|  Negative|             5507.0|             3969.0|\n",
      "+----------+-------------------+-------------------+\n",
      "\n",
      "Precision = 0.85083\n",
      "Recall = 0.95248\n",
      "F1 Score = 0.89879\n",
      " \n",
      "Label 1, raining tomorrow\n",
      " \n",
      "+----------+-------------------+-------------------+\n",
      "|True value|Positive(predicted)|Negative(predicted)|\n",
      "+----------+-------------------+-------------------+\n",
      "|  Positive|             3969.0|             5507.0|\n",
      "|  Negative|             1567.0|            31410.0|\n",
      "+----------+-------------------+-------------------+\n",
      "\n",
      "Precision = 0.71694\n",
      "Recall = 0.41885\n",
      "F1 Score = 0.52878\n",
      " \n",
      "Summary Stats for overall\n",
      "Precision = 0.83337\n",
      "Recall = 0.83337\n",
      "F1 Score = 0.83337\n",
      " \n",
      " \n",
      " \n",
      "This is for  RandomForestClassifier\n",
      " \n",
      "Label 0, Not raining tomorrow\n",
      " \n",
      "+----------+-------------------+-------------------+\n",
      "|True value|Positive(predicted)|Negative(predicted)|\n",
      "+----------+-------------------+-------------------+\n",
      "|  Positive|            31954.0|             1023.0|\n",
      "|  Negative|             6067.0|             3409.0|\n",
      "+----------+-------------------+-------------------+\n",
      "\n",
      "Precision = 0.84043\n",
      "Recall = 0.96898\n",
      "F1 Score = 0.90014\n",
      " \n",
      "Label 1, raining tomorrow\n",
      " \n",
      "+----------+-------------------+-------------------+\n",
      "|True value|Positive(predicted)|Negative(predicted)|\n",
      "+----------+-------------------+-------------------+\n",
      "|  Positive|             3409.0|             6067.0|\n",
      "|  Negative|             1023.0|            31954.0|\n",
      "+----------+-------------------+-------------------+\n",
      "\n",
      "Precision = 0.76918\n",
      "Recall = 0.35975\n",
      "F1 Score = 0.49022\n",
      " \n",
      "Summary Stats for overall\n",
      "Precision = 0.83299\n",
      "Recall = 0.83299\n",
      "F1 Score = 0.83299\n",
      " \n",
      " \n",
      " \n",
      "This is for  LogisticRegression\n",
      " \n",
      "Label 0, Not raining tomorrow\n",
      " \n",
      "+----------+-------------------+-------------------+\n",
      "|True value|Positive(predicted)|Negative(predicted)|\n",
      "+----------+-------------------+-------------------+\n",
      "|  Positive|            31375.0|             1602.0|\n",
      "|  Negative|             6075.0|             3401.0|\n",
      "+----------+-------------------+-------------------+\n",
      "\n",
      "Precision = 0.83778\n",
      "Recall = 0.95142\n",
      "F1 Score = 0.89099\n",
      " \n",
      "Label 1, raining tomorrow\n",
      " \n",
      "+----------+-------------------+-------------------+\n",
      "|True value|Positive(predicted)|Negative(predicted)|\n",
      "+----------+-------------------+-------------------+\n",
      "|  Positive|             3401.0|             6075.0|\n",
      "|  Negative|             1602.0|            31375.0|\n",
      "+----------+-------------------+-------------------+\n",
      "\n",
      "Precision = 0.67979\n",
      "Recall = 0.35891\n",
      "F1 Score = 0.46978\n",
      " \n",
      "Summary Stats for overall\n",
      "Precision = 0.81916\n",
      "Recall = 0.81916\n",
      "F1 Score = 0.81916\n",
      " \n",
      " \n",
      " \n",
      "This is for  GBTClassifier\n",
      " \n",
      "Label 0, Not raining tomorrow\n",
      " \n",
      "+----------+-------------------+-------------------+\n",
      "|True value|Positive(predicted)|Negative(predicted)|\n",
      "+----------+-------------------+-------------------+\n",
      "|  Positive|            31446.0|             1531.0|\n",
      "|  Negative|             5244.0|             4232.0|\n",
      "+----------+-------------------+-------------------+\n",
      "\n",
      "Precision = 0.85707\n",
      "Recall = 0.95357\n",
      "F1 Score = 0.90275\n",
      " \n",
      "Label 1, raining tomorrow\n",
      " \n",
      "+----------+-------------------+-------------------+\n",
      "|True value|Positive(predicted)|Negative(predicted)|\n",
      "+----------+-------------------+-------------------+\n",
      "|  Positive|             4232.0|             5244.0|\n",
      "|  Negative|             1531.0|            31446.0|\n",
      "+----------+-------------------+-------------------+\n",
      "\n",
      "Precision = 0.73434\n",
      "Recall = 0.44660\n",
      "F1 Score = 0.55542\n",
      " \n",
      "Summary Stats for overall\n",
      "Precision = 0.84041\n",
      "Recall = 0.84041\n",
      "F1 Score = 0.84041\n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Run step09\n",
    "step09()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement of accuracy#\n",
    "\n",
    "\n",
    "1.Add more data: Presence of more data results in better and accurate models.\n",
    "\n",
    "2.Feature processing : choose better subset of attributes and use better normalization which will better explains the relationship of independent variables with target variable. \n",
    "\n",
    "3.Algorithm Tuning : Take different values for the algorithm parameters into account.For instant,In random forest, we have various parameters like max_features, number_trees, random_state, oob_score and others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
